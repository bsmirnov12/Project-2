{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UT-TOR-DATA-PT-01-2020-U-C Group Project 2\n",
    "# Scrape https://acharts.co/canada_singles_top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite Database related imports\n",
    "import sqlalchemy\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, event, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping related imports\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations\n",
    "\n",
    "### DB access initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on PRAGMA foreign_keys to enforce foregn key constraints (it is disabled by default in SQLite)\n",
    "@event.listens_for(Engine, \"connect\")\n",
    "def set_sqlite_pragma(dbapi_connection, connection_record):\n",
    "    cursor = dbapi_connection.cursor()\n",
    "    cursor.execute(\"PRAGMA foreign_keys=ON\")\n",
    "    cursor.close()\n",
    "\n",
    "# Create engine to access the database\n",
    "engine = create_engine(\"sqlite:///../data/CanadaTop100.sqlite\")\n",
    "\n",
    "# Reflect an existing database into a new model\n",
    "AutomapBase = automap_base()\n",
    "\n",
    "# Reflect the tables\n",
    "AutomapBase.prepare(engine, reflect=True)\n",
    "\n",
    "# Save references to each table\n",
    "Artist = AutomapBase.classes.Artist\n",
    "Chart = AutomapBase.classes.Chart\n",
    "Song = AutomapBase.classes.Song\n",
    "Performed_by = AutomapBase.classes.Performed_by\n",
    "\n",
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)\n",
    "\n",
    "# Debug output\n",
    "#AutomapBase.classes.items()\n",
    "#list(inspect(Artist).columns)\n",
    "#list(inspect(Chart).columns)\n",
    "#list(inspect(Song).columns)\n",
    "#list(inspect(Performed_by).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://acharts.co/canada_singles_top_100'\n",
    "archive_url = base_url + '#archive'\n",
    "browser = Browser('chrome', executable_path='chromedriver.exe', headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if this week was already saved into the database\n",
    "# Returnes true if the year+week data is in the Chart table, false otherwise\n",
    "def in_database(year, week):\n",
    "    count = session.query(Chart).filter_by(year=year, week=week).count()\n",
    "    return count > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the song is in the Song table.\n",
    "# Returnes song_id or Null if the song isn't in the table\n",
    "def check_song(song, performed_by):\n",
    "    song_id = session.query(Song.id).filter_by(song_name=song, performed_by=performed_by).scalar()\n",
    "    #print(f\"Checking: song='{song}', performed_by='{performed_by}', id={song_id}\")\n",
    "    return song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds new song to the Song table\n",
    "# Returns song_id\n",
    "def insert_song(song, performed_by):\n",
    "    session.add(Song(song_name=song, performed_by=performed_by))\n",
    "    session.commit()\n",
    "    song_id = session.query(Song.id).filter_by(song_name=song, performed_by=performed_by).scalar()\n",
    "    #print(f\"New song: song='{song}', performed_by='{performed_by}', id={song_id}\")\n",
    "    return song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks all artists in the Artist table, inserts new artists.\n",
    "# Returnes a list of artist ids\n",
    "def check_artists(artists):\n",
    "    artist_ids = []\n",
    "    \n",
    "    for artist in artists:\n",
    "        artist_id = session.query(Artist.id).filter_by(name=artist).scalar()\n",
    "        #print(f\"Existing artist: name={artist}, id={artist_id}\")\n",
    "        \n",
    "        if not artist_id:\n",
    "            session.add(Artist(name=artist))\n",
    "            session.commit()\n",
    "            artist_id = session.query(Artist.id).filter_by(name=artist).scalar()\n",
    "            #print(f\"New artist: name={artist}, id={artist_id}\")\n",
    "\n",
    "        artist_ids.append(artist_id)\n",
    "\n",
    "    #print(f\"List of artist ids: {artist_ids}\")\n",
    "    return artist_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds entries to the Performed_by table for a new song\n",
    "def insert_performers(song_id, artists):\n",
    "    artist_ids = check_artists(artists)\n",
    "    rows = []\n",
    "    for idx, artist_id in enumerate(artist_ids):\n",
    "        rows.append(Performed_by(song_id=song_id, artist_id=artist_id, order=idx))\n",
    "    session.add_all(rows)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds a song in the Chart table\n",
    "def update_chart(year, week, position, song_id):\n",
    "    session.add(Chart(year=year, week=week, position=position, song_id=song_id))\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes one row of a chart table\n",
    "# Parameters: year, week and row DOM node\n",
    "def add_chart_row(year, week, row):\n",
    "    # Parsing the row with song information\n",
    "    pos_node = row.find('td', class_='cNum')\n",
    "    position = pos_node.find('span', itemprop='position').string\n",
    "\n",
    "    hit_node = row.find('td', class_='cPrinciple')\n",
    "    song = hit_node.find('span', itemprop='name').string\n",
    "\n",
    "    performed_node = hit_node.br.find_next('span')\n",
    "    performed_by = ' '.join(performed_node.stripped_strings)\n",
    "\n",
    "    artists = []\n",
    "    for artist in performed_node.find_all('span', itemprop='name'):\n",
    "        artists.append(artist.string)\n",
    "\n",
    "    # Ad Hoc corrections - working around data bugs\n",
    "    # Bug #1: 2018/46, position 88\n",
    "    if len(artists) == 3 and artists[1] == 'Jack' and artists[2] == 'Jack':\n",
    "        artists = artists[:2]\n",
    "        artists[1] = 'Jack & Jack'\n",
    "        \n",
    "    #print(f\"year={year}, week={week}, position={position}, song='{song}', performed_by='{performed_by}', artists={artists}\")\n",
    "    \n",
    "    # Saving the row in the database\n",
    "    song_id = check_song(song, performed_by)\n",
    "    if not song_id:\n",
    "        song_id = insert_song(song, performed_by)\n",
    "        insert_performers(song_id, artists)\n",
    "\n",
    "    update_chart(year, week, position, song_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape one week chart\n",
    "# Parameters: year, week\n",
    "def scrape_week(year, week):\n",
    "    week_url = f\"{base_url}/{year}/{week}\"\n",
    "    browser.visit(week_url)\n",
    "    soup = BeautifulSoup(browser.html, 'lxml')\n",
    "\n",
    "    chart = soup.find('table', id='ChartTable').tbody\n",
    "    if not chart:\n",
    "        print(\"Didn't find 'table' element on the chart page.\\nDEBUG:\")\n",
    "        print(soup)\n",
    "        return False\n",
    "\n",
    "    rows = chart.find_all('tr')\n",
    "    if rows is None: # Data bug #2: week 53 2009, 96 songs\n",
    "        print(f\"Chart table rows not found.\\nDEBUG:\")\n",
    "        print(chart)\n",
    "        return False\n",
    "        \n",
    "    for row in rows:\n",
    "        add_chart_row(year, week, row)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all weeks and years\n",
    "browser.visit(archive_url)\n",
    "soup = BeautifulSoup(browser.html, 'lxml')\n",
    "select_node = soup.find('select', id='SelectWeek')\n",
    "option_nodes = select_node.find_all('option')\n",
    "weeks = [option['value'] for option in option_nodes]\n",
    "weeks.reverse() # reversing the list to start from the most recent charts and go back to the oldest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the week strings (in the form \"year/week\") and scraping all of them one by one\n",
    "for week_str in weeks:\n",
    "    year, week = week_str.split('/')\n",
    "    if not in_database(year, week):\n",
    "        print(\"Scraping week \" + week_str)\n",
    "        time.sleep(3)\n",
    "        if not scrape_week(year, week):\n",
    "            print(\"Something went wrong. Stopping...\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Skipping week \" + week_str + \" - already in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PythonData] *",
   "language": "python",
   "name": "conda-env-.conda-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
